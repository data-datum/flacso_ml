---
title: "Practica 1 - Introducción a ML y tidymodels"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Mi primer modelo de Machine Learning

## Dataset

El dataset corresponde a Boston, que se encuentra disponible en Kaggle; una plataforma de competencia de machine learning. 
Más info en: 

#### Cargo las librerias

```{r eval=FALSE}
#si no tengo instalado la libreria, la instalo
install.packages(tidymodels)
```


```{r warning=FALSE, message=FALSE}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(corrr)
library(MASS)
```

#### Ingreso los datos

```{r}
data(Boston)
```

```{r}
head(Boston) #veamos el encabezado del dataset
```



```{r}
glimpse(Boston)
```

Como podemos ver, todas las variables son cuantitativas continuas, lo que nos facilita no tener que codificarlas (en el caso que sean categóricas).
Las variables (columnas) en total son 14; de las cuales una es la variable que nos interesa predecir, en este caso, **medv**. Las otras variables van a ser las variables para nuestro modelo. 

### *Breve descripción de las variables*
(https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html)

*crim*: tasa de criminalidad per cápita por ciudad.

*zn*: proporción de terreno residencial dividido en zonas para lotes de más de 25,000 pies cuadrados.

*indus*: proporción de acres comerciales no minoristas por ciudad.

*chas*: Variable ficticia de Charles River (= 1 si el tramo limita con el río; 0 en caso contrario).

*nox*: concentración de óxidos de nitrógeno (partes por 10 millones).

*rm*: número medio de habitaciones por vivienda.

*age*: Proporción de unidades ocupadas por sus propietarios construidas antes de 1940.

*dis*: media ponderada de las distancias a cinco centros de empleo de Boston.

*rad*:índice de accesibilidad a carreteras radiales.

*tax*: Tasa de impuesto a la propiedad de valor total por \ $ 10,000.

*ptratio*: Proporción alumno-profesor por ciudad.

*black*: 1000 (Bk - 0.63) ^ 2 donde Bk es la proporción de negros por ciudad.

*lstat*: estatus más bajo de la población (porcentaje).

*medv*: valor medio de las viviendas ocupadas por sus propietarios en \ $ 1000



## Pequeño análisis exploratorio de toda la base de datos 
Esta etapa nos ayuda a visualizar distribuciones de probabilidad de las variables, si hay algun outlier y demás. 

```{r}
cor(Boston)
```




### Vamos a dividir los datos

En esta instancia se deben dividir los datos en train y test. 
Como nos proporcionan separados ambos datasets, no debemos preocuparnos, pero si es importante en esta instancia, dividirlos. 

```{r}
p_split <- Boston %>%
  initial_split(prop=0.75) # divido en 75%
p_train <- training(p_split)
p_split
```


```{r}
p_folds <- vfold_cv(p_train, v=3)
```


## Receta

Con este nombre agrupamos todos los pre-procesamientos que vamos a realizar al dataset de *train*, con lo cual haremos el modelado. Estas mismas operaciones se realizan al final en el dataset de *test*.

```{r}
recipe_dt <- p_train %>%
  recipe(medv~.) %>%
  step_corr(all_predictors()) %>% #elimino las correlaciones
  step_center(all_predictors(), -all_outcomes()) %>% #centrado
  step_scale(all_predictors(), -all_outcomes()) %>% #escalado
  prep() 
```

```{r}
recipe_dt
```



## Modelo
```{r}
set.seed(123)
tree_spec <- decision_tree() %>% #arboles de decisión
  set_engine("rpart") %>% #librería rpart
  set_mode("regression") #modo para clasificar
tree_spec
```


```{r}
tree_wf <- workflow() %>%
  add_recipe(recipe_dt) %>% #agrego la receta
  add_model(tree_spec) #agrego el modelo
tree_wf
```

### Error de estimacion del modelo en TRAIN
```{r}
set.seed(123) 
tree_spec %>% 
  fit_resamples(medv ~ ., 
                resamples = p_folds) %>% 
  collect_metrics()
```

### Error de estimación del modelo en TEST

```{r}
final_fit_dt <- last_fit(tree_wf,
  split = p_split
)
final_fit_dt %>%
  collect_metrics()
```

```{r}
collect_predictions(final_fit_dt) %>%
  ggplot(aes(medv, .pred)) +
  geom_abline(lty = 2, color = "gray50") +
  geom_point(alpha = 0.5, color = "midnightblue") +
  coord_fixed()
```

Hay mucho para mejorar nuestro modelo, eso lo veremos en la siguiente clase :)


