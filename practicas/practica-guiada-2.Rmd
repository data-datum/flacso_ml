---
title: "Practica guiada 2 - Tunning de árboles"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Tunning de Árboles de Decisión con Tidymodels

## Dataset

El dataset corresponde a Boston, que se encuentra disponible en Kaggle; una plataforma de competencia de machine learning. 
Más info en: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html 

#### Cargo las librerias

```{r eval=FALSE}
#si no tengo instalado la libreria, la instalo
#install.packages(tidymodels)
```


```{r warning=FALSE, message=FALSE}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(corrr)
library(MASS) #el dataset se encuentra en esta librería 
```

#### Ingreso los datos

```{r}
data(Boston)
```

### División de los datos

En primera instancia dividimos en TRAIN Y TEST
```{r}
set.seed(1234)
p_split <- Boston %>%
    initial_split(prop = 0.75)
p_train <- training(p_split)
p_test <- testing(p_split)

glimpse(p_train)
```


```{r}
p_split
```

```{r}
head(p_test)
```


#### Voy a crear los folds de validación cruzada a partir de los datos de TRAIN
```{r}
p_folds <- vfold_cv(p_train, v=3)
```

```{r}
p_folds 
```



### Preprocesamiento

```{r}
recipe_dt <- p_train %>%
  recipe(medv~.) %>%
  step_corr(all_predictors()) %>% #elimino las correlaciones
  step_center(all_predictors(), -all_outcomes()) %>% #centrado
  step_scale(all_predictors(), -all_outcomes()) %>% #escalado
  prep() 
```


### Modelo
 
Aca vamos a especificar las variables que vamos a hacer tunning de estas variables. 

```{r}
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("regression")

tree_spec
```

Veamos los posibles valores en esta grilla. 
```{r}
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 4)

tree_grid
```


### Tunning del modelo de árboles de decisión

En esta etapa vamos a hacer el tuneo de los hiperparámetros que hemos definido anteriormente. Vamos a consignar las métricas de regresión usuales. 

**Importante**: Los datos son los folds de la validación cruzada. 
```{r}
doParallel::registerDoParallel() #paralelizamos los cálculos

set.seed(345)
tree_rs <- tune_grid(
  tree_spec,
  medv ~ .,
  resamples = p_folds,
  grid = tree_grid,
  metrics = metric_set(rmse, rsq, mae)
)

tree_rs
```

## Predicciones en TRAIN
```{r}
collect_metrics(tree_rs)
```

```{r}
tree_rs %>%
  collect_metrics(summarize=TRUE)
```




#### Ploteamos los hiperparámetros

Vamos a plotear los 3 hiperparámetros q hicimos tunning, lo hacemos mediante la función autoplot() disponible en tidymodels. 
```{r}
autoplot(tree_rs) 
```

# El mejor modelo
```{r}
show_best(tree_rs)
```

## Finalizamos el modelo
```{r}
final_tree <- finalize_model(tree_spec, select_best(tree_rs, "rmse"))

final_tree
```


## Resultados en TEST

Mediante la función **last_fit()** de tidymodels, lo que hacemos es fitear el mejor modelo y devolver los resultados en TEST. 


```{r}
final_rs <- last_fit(final_tree, medv ~ ., p_split)
final_rs
```


### Metricas en TEST set
```{r}
final_rs %>%
  collect_metrics()
```



Podemos ver las predicciones del modelo en TEST mediante la función **collect_predictions()**.
```{r}
final_rs %>%
  collect_predictions()
```



```{r}
collect_predictions(final_rs) %>%
  ggplot(aes(medv, .pred)) +
  geom_abline(lty = 2, color = "gray50") +
  geom_point(alpha = 0.5, color = "midnightblue") +
  coord_fixed()
```





