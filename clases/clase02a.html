<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>clase02a.utf8</title>
    <meta charset="utf-8" />
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


background-image: url(img/portada-flacso.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle



























# Machine Learning en Aplicaciones Espaciales


### Clase 2a



---

## Que vemos hoy


### Repaso de M칠tricas 
#### F1 score / AUC Curva / Precision - Recall Curva


### 츼rboles de decisi칩n (Tunning)


### Random Forest (teor칤a y pr치ctica)


---

# Repaso de M칠tricas

---


## Matriz de confusi칩n

        
&lt;img src="img/conf-m.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Exactitud (accuracy)
        
&lt;img src="img/conf-m2.png" width="90%" style="display: block; margin: auto;" /&gt;



---

## Precision

        
&lt;img src="img/conf-m3.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Recall

       
&lt;img src="img/conf-m4.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Repaso

       
&lt;img src="img/metrics00.png" width="90%" style="display: block; margin: auto;" /&gt;

---



## Precision vs Recall 

* Uno podria elegir trabajar con las m칠tricas de Precision o Recall para un problema desbalanceado. 
Maximinar la precisi칩n minimizar치 los FALSOS POSITIVOS, mientras que el Recall minimizar치 los FALSOS
NEGATIVOS. 
* Entonces, podria ser adecuado trabajar con:

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Precisi칩n: Cuando el objetivo es minimizar los falsos positivos. 


#### Recall: Cuando el objetivo es minimizar los falsos negativos. 


]



---

## F score


La medida F equilibra la precisi칩n y el recall. En algunos problemas, puede que nos interese
en una medida F con m치s atenci칩n puesta en la precisi칩n, como cuando los falsos positivos son m치s  importante minimizar, pero los falsos negativos siguen siendo importantes. En otros problemas, podr칤amos estar interesados en una medida F con m치s atenci칩n puesta en el recall, como cuando los falsos negativos son m치s importantes minimizar, pero los falsos positivos siguen siendo importantes.
La soluci칩n es la medida Fbeta (medida F ). 
--
La medida Fbeta es una abstracci칩n de la medida F donde el equilibrio de precisi칩n y recall en el c치lculo de la media arm칩nica est치 controlado por un coeficiente llamado beta ().


&lt;img src="img/fbeta.png" width="60%" style="display: block; margin: auto;" /&gt;

* F0.5-measure ( = 0.5): Mayor peso en la **precisi칩n**, menos peso en el recall. 
* F1-measure ( = 1): **Balance del peso en la precisi칩n y el recall**.
* F2-measure ( = 2): Menor peso en la precisi칩n, mas peso en el **recall**.

.footnote[*Imbalanced classification with Python. Jason Brownlee*]

---

## F1 score


**Cuando me interesan tanto los FP como los FN, de igual forma**, voy a utilizar el F1-score. 

&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;img src="img/f1.svg" width="80%" style="display: block; margin: auto;" /&gt;

.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---

### Entendamos el F1-Score

Supongamos que tenemos una m치quina recolectora de frutas, siendo que algunas de ellas est치n maduras y otras no. 


  
&lt;img src="img/ripe-apples.png" width="80%" style="display: block; margin: auto;" /&gt;



.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---


&lt;img src="img/apple-ripe2.png" width="50%" style="display: block; margin: auto;" /&gt;



&lt;img src="img/f1-c.png" width="80%" style="display: block; margin: auto;" /&gt;


.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]


---

## F2 score

Imaginemos que hemos tenemos un clasificador de mamograf칤as. Lo probamos en una serie de diez mamograf칤as.




&lt;img src="img/mamm1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

En una segunda instancia tenemos esta matriz de confusi칩n. 
**Si prestamos atenci칩n, los TP y los TN siguen siendo los mismos en ambos casos, pero hubo un cambio en los FP y FN**

&lt;img src="img/f2-mammogram.png" width="60%" style="display: block; margin: auto;" /&gt;

--

**쯈u칠 tipo de error es m치s grave? 쯋n FP o FN?**

--

Claramente un **FALSO NEGATIVO**, debo poner un 칠nfasis en el **recall**.

---


&lt;img src="img/f2.png" width="90%" style="display: block; margin: auto;" /&gt;





---
### Importante  游눠


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

### La accuracy o exactitud es una m칠trica apropiada en datasets balanceados. 

### En caso de estar lidiando con datasets desbalanceados deberemos usar la m칠trica apropiada (o balancear nuestros datos).  

]

.footnote[*https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/*]


---

### Importante  游눠


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

## Determinar que error es m치s grave (FP o FN) lo determina el contexto de aplicaci칩n del problema.

Veamos un ejemplo pr치ctico
]


---

## FP vs FN



&lt;img src="img/cia-market.png" width="70%" style="display: block; margin: auto;" /&gt;


Consideremos dos clientes potenciales de un sistema de huellas dactilares. 

* Uno es un **supermercado** que lo usar치 en el mostrador de pago para verificar que usted es miembro
de un programa de descuento. 
* El otro es la **CIA** que lo usar치 en la entrada de una instalaci칩n, para verificar que Ud es personal autorizado para ingresar a esa instalaci칩n.

.footnote[Fuente: *Learning from data*]
---

### FP vs FN


* Para el supermercado, un **falso rechazo (falso negativo) es costoso** porque si un cliente recibe un 
rechazo err칩neamente, puede desanimarse de seguir siendo cliente en el futuro. 
* Por otro lado, el costo de una **falsa aceptaci칩n (falso positivo) es menor**. El supermercado regala un descuento a alguien que no se lo merec칤a, sin mayores prejuicios para el supermercado. 


.footnote[Fuente: *Learning from data*]

--



&lt;img src="img/MARKET.png" width="100%" style="display: block; margin: auto;" /&gt;



.footnote[Fuente: *Learning from data*]

---

### FP vs FN

* Para la CIA, sin embargo, una **falsa aceptaci칩n (falso positivo) es un desastre**. Una persona no autorizada se beneficiar치 del acceso a una instalaci칩n muy sensible. 
* **El falso rechazo (falso negativo)**, sin embargo, **puede tolerarse**, ya que las personas autorizadas son empleados (en lugar de clientes como el caso del supermercado).


.footnote[Fuente: *Learning from data*]

--



&lt;img src="img/CIA.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *Learning from data*]



---


## Repaso Curva AUC


.right-column[
**Una curva ROC es apropiada cuando**:
- Quiero ver la performance global del modelo. 
- Quiero comparar diferentes modelos a diferentes thresholds (umbrales).

- Los valores m치s peque침os en el eje x del gr치fico indican menos FP y m치s TN.
- Los valores m치s grandes en el eje y del gr치fico indican m치s TP  y menos FN.
]


---

## Curva Precision - Recall 

* La curva de Precision-Recall muestra la compensaci칩n entre precisi칩n y recall para diferentes umbrales. Un 치rea alta debajo de la curva representa tanto una alta recall como una alta precisi칩n, donde la alta precisi칩n se relaciona con una tasa baja de falsos positivos y el alto recall se relaciona con una tasa baja de falsos negativos. Los puntajes altos para ambos muestran que el clasificador est치 arrojando resultados precisos (alta precisi칩n), as칤 como tambi칠n arroja la mayor칤a de todos los resultados positivos (alta recall).

* Un sistema con alta recall pero baja precisi칩n arroja muchos resultados, pero la mayor칤a de las etiquetas previstas son incorrectas en comparaci칩n con las etiquetas de entrenamiento. Un sistema con alta precisi칩n pero poca recall es todo lo contrario, arrojando muy pocos resultados, pero la mayor칤a de las etiquetas predichas son correctas en comparaci칩n con las etiquetas de entrenamiento. Un sistema ideal con alta precisi칩n y alta recall devolver치 muchos resultados, con todos los resultados etiquetados correctamente.


.footnote[https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html]

---

## Curva Precision - Recall

Como podemos ver al aumentar la AUC en clases balanceadas, tambi칠n aumenta el score en la curva Precision-Recall

![](https://raw.githubusercontent.com/dariyasydykova/open_projects/master/ROC_animation/animations/PR.gif) 


.footnote[*https://paulvanderlaken.com/2019/08/16/roc-auc-precision-and-recall-visually-explained/*]
---

## Curvas Precision - Recall 

Veamos que sucede con el desbalanceo de clase. 

![](https://raw.githubusercontent.com/dariyasydykova/open_projects/master/ROC_animation/animations/imbalance.gif) 

**Como se observa la AUC no se ve casi influenciada por el desbalanceo, lo que nos da una idea que no es una m칠trica apropiada cuando el desbalanceo de las clases es severo.**


.footnote[*https://paulvanderlaken.com/2019/08/16/roc-auc-precision-and-recall-visually-explained/*]

---

## Quizz 






---

## Tunning de Hiperpar치metros

Cuando hacemos tunning de hiperpar치metros, lo que hacemos es encontrar valores 칩ptimos para un modelo de regresi칩n o clasificaci칩n. 


Esa b칰squeda la podemos hacer **en grilla (grid search)** o **random (aleatoria)**
--

&lt;img src="img/grid-random-search.png" width="80%" style="display: block; margin: auto;" /&gt;





---
class: inverse, center, middle 

## 츼rboles de decisi칩n 

## 쮺칩mo se deciden los splits?


---

## Entrop칤a

La entrop칤a es una medida de la aleatoriedad de la informaci칩n que se procesa. **Cuanto mayor sea la entrop칤a, m치s dif칤cil ser치 sacar conclusiones de esa informaci칩n.**

El concepto de entrop칤a viene del campo de la teor칤a de la informaci칩n. 


&lt;img src="img/entropy-math-eq.png" width="40%" style="display: block; margin: auto;" /&gt;


&lt;img src="img/entropy2.png" width="80%" style="display: block; margin: auto;" /&gt;


---

## Entrop칤a


&lt;img src="img/shannon.png" width="80%" style="display: block; margin: auto;" /&gt;



--
A partir del gr치fico anterior, es bastante evidente que la entrop칤a es cero cuando la probabilidad es 0 o 1. La entrop칤a es m치xima cuando la probabilidad es 0.5 porque proyecta una aleatoriedad perfecta en los datos y no hay posibilidad si determinando perfectamente el resultado.



---

### Ganancia de Informaci칩n (Information Gain)


La ganancia de informaci칩n es una propiedad estad칤stica que mide qu칠 tan bien un atributo determinado separa los ejemplos de entrenamiento de acuerdo con su clasificaci칩n de destino. La construcci칩n de un 치rbol de decisiones consiste en encontrar un atributo que devuelva la **mayor ganancia de informaci칩n y la menor entrop칤a.**



`\(IG = Entropy(parent) - weighted \hspace{1mm} average [Entropy (children)]\)`


--



&lt;img src="img/IG.png" width="80%" style="display: block; margin: auto;" /&gt;


---

### Veamos como funciona en un 치rbol de decisi칩n 

Supongamos que tenemos que decidir si entregar o no un pr칠stamo, y tenemos 2 variables para decidir si lo hacemos:

* Balance:
* Residence:


---


&lt;img src="img/entropy-balance.png" width="70%" style="display: block; margin: auto;" /&gt;


---


&lt;img src="img/entrop-balance.png" width="70%" style="display: block; margin: auto;" /&gt;


---


&lt;img src="img/entropy-residence.png" width="90%" style="display: block; margin: auto;" /&gt;


---




&lt;img src="img/entrop-residenc.png" width="80%" style="display: block; margin: auto;" /&gt;

---


## Conclusi칩n

Cuanto m치s homogeneas son las ramas del 치rbol que se genera al seleccionar el algoritmo una variable, 

* hay mayor ganancia de informaci칩n.

&lt;br&gt;

* hay menos entrop칤a 

&lt;br&gt;&lt;br&gt;

**Eso se traduce en un mejor modelo para la predicci칩n que deseamos realizar**

---

## Relaci칩n de Ganancia (Gain Ratio)




---

## 칈ndice de Gini (Index Gini)





---

## Tunning de hiperpar치metros en 츼rboles de decisi칩n 

* Vamos a hacer tunning de los hiperpar치metros del modelo. 
Documentaci칩n: https://parsnip.tidymodels.org/reference/decision_tree.html 

#### Hiperpar치metros del modelo:
&lt;br&gt;
* **cost_complexity**: Un n칰mero positivo para el par치metro de costo / complejidad 

&lt;br&gt;
* **tree_depth**: Un n칰mero entero para la profundidad m치xima del 치rbol.

&lt;br&gt;
* **min_n**: Un n칰mero entero para el n칰mero m칤nimo de puntos de datos en un nodo que se requieren para que el nodo se divida m치s.


---

## B칰squeda en grilla (grid search)






```r
set.seed(123) 
trees_spec &lt;- decision_tree() %&gt;% 
  set_engine("rpart") %&gt;% 
  set_mode("classification") %&gt;% 
  set_args(min_n = tune(),
           cost_complexity = tune(),
           tree_depth= tune())
```


---
## B칰squeda random

En **set_args()** voy a especificar los hiperpar치metros y dejarlos variar libremente con la funcion tune().



```r
set.seed(123) 
trees_spec &lt;- decision_tree() %&gt;% 
  set_engine("rpart") %&gt;% 
  set_mode("classification") %&gt;% 
  set_args(min_n = tune(),
           cost_complexity = tune(),
           tree_depth= tune())
```



---

## B칰squeda en grilla




---

class: inverse, center, middle

## Manos en R!


---


class: inverse, center, middle

## Ensembles


---

## Ensembles


Con el nombre de ensembles se conocen a los modelos de:

--
* Variedades de Bagging (Bagged Trees, Random Forest)

--
* Variedades de Boosting (Adaboost, XGBoost)

--

La idea es combinar modelos simples (치rboles de decisi칩n) para lograr una mejor predicci칩n. 

--

Usados en regresi칩n y clasificaci칩n.

---

## Bagging para clasificaci칩n

* Tambi칠n llamado *bootstrap resampling*. 


.left-column[
&lt;img src="img/bagging0.svg" width="400%" style="display: block; margin: auto;" /&gt;


]

.right-column[

&lt;img src="img/bagging.svg" width="100%" style="display: block; margin: auto;" /&gt;

]



---
## Bagging para clasificaci칩n

.left-column[
&lt;img src="img/bagging0.svg" width="100%" style="display: block; margin: auto;" /&gt;


]

.right-column[

&lt;img src="img/bagging_line.svg" width="200%" style="display: block; margin: auto;" /&gt;


&lt;img src="img/bagging_trees.svg" width="200%" style="display: block; margin: auto;" /&gt;


]


---

## Bagging para clasificaci칩n



.left-column[
&lt;img src="img/bagging0_cross.svg" width="100%" style="display: block; margin: auto;" /&gt;


]

.right-column[

&lt;img src="img/bagging_cross.svg" width="120%" style="display: block; margin: auto;" /&gt;


&lt;img src="img/bagging_trees_predict.svg" width="120%" style="display: block; margin: auto;" /&gt;


&lt;img src="img/bagging_vote.svg" width="120%" style="display: block; margin: auto;" /&gt;


]


---


## Baggging para regresi칩n



---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
