<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>clase02a.utf8</title>
    <meta charset="utf-8" />
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


background-image: url(img/portada-flacso.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle



























# Machine Learning en Aplicaciones Espaciales


### Clase 2a. M칠tricas. 츼rboles de Decisi칩n



---

## Hoja de Ruta

#### Intro te칩rica

* Principios del aprendizaje

* Repaso de M칠tricas (F1 score / AUC Curva / Precision - Recall Curva)

* 츼rboles de decisi칩n (Tunning)

--

#### Pr치ctica guiada

--

#### Recreo  游꼿

--

#### Manos en R! 游눹

--

#### Ensembles. Introducci칩n a Random Forest



---

class: inverse, center, middle

## Principios del aprendizaje


---

### 1. Navaja de Occam 游댥


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[

### El modelo m치s simple que pueda ser ajustado es el m치s factible.

#### Si tuvi칠ramos para elegir entre un modelo simple y uno complejo con el mismo desempe침o, debo preferir **siempre** el modelo m치s simple
]




.footnote[__Learning from data__ Abu-Mostafa, Y.]

---

## Occam y Principio de Parsimonia


        
&lt;img src="img/pedro.png" width="90%" style="display: block; margin: auto;" /&gt;




.footnote[Fuente: https://pedromdd.medium.com/ten-myths-about-machine-learning-d888b48334a3]
---


### 2. Bias en el muestreo (sampling bias)


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[

### Si los datos contienen un sesgo, el algoritmo tendr치 ese mismo sesgo.
]


.footnote[__Learning from data__ Abu-Mostafa, Y.]

---


### 3. Data snooping  游

.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[

### El set de datos de testeo no debe usarse nunca durante la fase de entrenamiento, ya que esto arrojar치 resultados m치s optimistas que los esperados. 
]

.footnote[__Learning from data__ Abu-Mostafa, Y.]

---
class: inverse, center, middle

# Repaso de M칠tricas

---

## MAE (Error absoluto medio)



&lt;img src="img/mae-n.jpg" width="70%" style="display: block; margin: auto;" /&gt;


**Es la media de la diferencia absoluta entre el valor observado y los valores predichos.**
El error absoluto medio o MAE es un puntaje lineal, lo que significa que todas las diferencias individuales se ponder치n por igual en el promedio. 
Por ejemplo, la diferencia entre 0 y 10 es el doble de la diferencia entre 0 y 5.

**Es robusto a outliers**


---

## MSE (Error cuadr치tico medio)


&lt;img src="img/mse.jpg" width="60%" style="display: block; margin: auto;" /&gt;


**MSE es una funci칩n diferenciable** que facilita la realizaci칩n de operaciones matem치ticas en comparaci칩n con una funci칩n no diferenciable como MAE. Por lo tanto, en muchos modelos, RMSE se utiliza como m칠trica predeterminada para calcular la funci칩n de p칠rdida a pesar de ser m치s dif칤cil de interpretar que MAE.


---

## RSME (Raiz del error cuadr치tico medio)




&lt;img src="img/rmse.png" width="40%" style="display: block; margin: auto;" /&gt;


* Es la ra칤z cuadrada del MSE. La ra칤z cuadrada permite que los errores esten en la misma escala de medida del valor objetivo. 

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

* **Cuanto mas bajo sea el valor de MAE, MSE, RMSE, es mejor el modelo de regresi칩n.** 

]



---


## Matriz de confusi칩n

        
&lt;img src="img/conf-m.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Exactitud (accuracy)
        
&lt;img src="img/conf-m2.png" width="90%" style="display: block; margin: auto;" /&gt;



---

## Precision

        
&lt;img src="img/conf-m3.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Recall (o sensibilidad)

       
&lt;img src="img/conf-m4.png" width="90%" style="display: block; margin: auto;" /&gt;


---

## Resumiendo

       
&lt;img src="img/metrics00.png" width="90%" style="display: block; margin: auto;" /&gt;

---

## Para recordar mejor


       
&lt;img src="img/Error_Types_print.png" width="90%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *https://chrisalbon.com/*]


---


## Precision vs Recall 

* Uno podria elegir trabajar con las m칠tricas de Precision o Recall para un problema desbalanceado. 
Maximinar la precisi칩n minimizar치 los FALSOS POSITIVOS, mientras que el Recall minimizar치 los FALSOS
NEGATIVOS. 
* Entonces, podria ser adecuado trabajar con:

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Precisi칩n: Cuando el objetivo es minimizar los falsos positivos. 


#### Recall: Cuando el objetivo es minimizar los falsos negativos. 


]



---

## F score


**La medida F equilibra la precisi칩n y el recall.** 

**En algunos problemas, puede que nos interese en una medida F con m치s atenci칩n puesta en la precisi칩n**, como cuando los falsos positivos son m치s  importante minimizar, pero los falsos negativos siguen siendo importantes. **En otros problemas, podr칤amos estar interesados en una medida F con m치s atenci칩n puesta en el recall**, como cuando los falsos negativos son m치s importantes minimizar, pero los falsos positivos siguen siendo importantes.
La soluci칩n es la medida Fbeta. 

--



&lt;img src="img/fbeta.png" width="60%" style="display: block; margin: auto;" /&gt;

* F0.5-measure ( = 0.5): Mayor peso en la **precisi칩n**, menos peso en el recall. 
* F1-measure ( = 1): **Balance del peso en la precisi칩n y el recall**.
* F2-measure ( = 2): Menor peso en la precisi칩n, mas peso en el **recall**.

.footnote[*Imbalanced classification with Python. Jason Brownlee*]

---

## F1 score


**Cuando me interesan tanto los FP como los FN, de igual forma**, voy a utilizar el F1-score. 

&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;img src="img/f1.svg" width="80%" style="display: block; margin: auto;" /&gt;

.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---

### Entendamos el F1-Score

Supongamos que tenemos una m치quina recolectora de frutas, siendo que algunas de ellas est치n maduras y otras no. 


  
&lt;img src="img/ripe-apples.png" width="80%" style="display: block; margin: auto;" /&gt;



.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---


&lt;img src="img/apple-ripe2.png" width="50%" style="display: block; margin: auto;" /&gt;



&lt;img src="img/f1-c.png" width="80%" style="display: block; margin: auto;" /&gt;


.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]






---
### Importante  游눠


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

### La accuracy o exactitud es una m칠trica apropiada en datasets balanceados. 

### En caso de estar lidiando con datasets desbalanceados deberemos usar la m칠trica apropiada (o balancear nuestros datos).  

]

.footnote[*https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/*]


---


## Repaso Curva AUC




.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

**Una curva ROC es apropiada cuando**:
- Quiero ver la performance global del modelo. 
- Quiero comparar diferentes modelos a diferentes thresholds (umbrales).

- Los valores m치s peque침os en el eje x del gr치fico indican menos FP y m치s TN.
- Los valores m치s grandes en el eje y del gr치fico indican m치s TP  y menos FN.

]



---

 
&lt;img src="img/matriz-confusion.png" width="80%" style="display: block; margin: auto;" /&gt;



* Teniendo en mente el eje X y Y de la curva ROC, nuestro foco est치 en el TPR, el recall o la sensibilidad, y en el False Positive Rate, o tambi칠n 1-Especificidad. 



mientras que en la **curva Precision-Recall**:

* Precision
* Recall (Sensibilidad)

**De cierta forma, me esta interesando una sola clase, la clase positiva.** 


---

## Curva Precision - Recall 

* La curva de Precision-Recall muestra la compensaci칩n entre **precisi칩n y recall para diferentes umbrales**. Un 치rea alta debajo de la curva representa tanto una alta recall como una alta precisi칩n, donde la alta precisi칩n se relaciona con una tasa baja de falsos positivos y el alto recall se relaciona con una tasa baja de falsos negativos. Los puntajes altos para ambos muestran que el clasificador est치 arrojando resultados precisos (alta precisi칩n), as칤 como tambi칠n arroja la mayor칤a de todos los resultados positivos (alta recall).

* **Un sistema con alta recall** pero baja precisi칩n arroja muchos resultados, pero la mayor칤a de las etiquetas previstas son incorrectas en comparaci칩n con las etiquetas de entrenamiento. 

* **Un sistema con alta precisi칩n** pero poca recall es todo lo contrario, arrojando muy pocos resultados, pero la mayor칤a de las etiquetas predichas son correctas en comparaci칩n con las etiquetas de entrenamiento. 

* **Un sistema ideal con alta precisi칩n y alta recall** devolver치 muchos resultados, con todos los resultados etiquetados correctamente.


.footnote[https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html]

---

## Curva Precision - Recall

Como podemos ver al aumentar la AUC en clases balanceadas, tambi칠n aumenta el score en la curva Precision-Recall

![](https://raw.githubusercontent.com/dariyasydykova/open_projects/master/ROC_animation/animations/PR.gif) 


.footnote[*https://paulvanderlaken.com/2019/08/16/roc-auc-precision-and-recall-visually-explained/*]
---

## Curvas Precision - Recall 

Veamos que sucede con el desbalanceo de clase. 

![](https://raw.githubusercontent.com/dariyasydykova/open_projects/master/ROC_animation/animations/imbalance.gif) 

**Como se observa la AUC no se ve casi influenciada por el desbalanceo, lo que nos da una idea que no es una m칠trica apropiada cuando el desbalanceo de las clases es severo.**


.footnote[*https://paulvanderlaken.com/2019/08/16/roc-auc-precision-and-recall-visually-explained/*]

---

class: inverse, central, middle


## Bias-Variance Tradeoff


---

## Espacio de hip칩tesis

f: la funcion verdadera a estimar

g: la mejor funci칩n que puedo obtener mediante diferentes modelos

g{D1}, g{D2}, g{D3}: son las funciones que obtengo ajustando mediante un dataset


&lt;img src="img/bias-variance1.png" width="70%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: https://blog.insightdatascience.com/bias-variance-tradeoff-explained-fa2bc28174c4]



---

## Matem치ticamente


&lt;img src="img/bias-var.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: https://github.com/AntonMu/BiasVarianceTradeoff/blob/master/Bias_Variance_Tradeoff.pdf]


---

class: inverse, center, middle


## 쮺칩mo puedo controlar la complejidad de mi modelo?



---

class: inverse, center, middle


## Recordar
--

## La complejidad est치 determinada mediante:
--

## Par치metros

--

## Hiperpar치metros

---

class: inverse, center, middle


## Pero s칩lo tengo CONTROL 

--

## sobre los 

--

## HIPERPAR츼METROS 

--

## 쮺칩mo?

---

## Tunning de Hiperpar치metros

Cuando hacemos tunning de hiperpar치metros, lo que hacemos es encontrar valores 칩ptimos para un modelo de regresi칩n o clasificaci칩n. 


Esa b칰squeda la podemos hacer **en grilla (grid search)** o **random (aleatoria)**
--

&lt;img src="img/grid-random-search.png" width="80%" style="display: block; margin: auto;" /&gt;


---

class: inverse, center, middle


## 쮺칩mo queda nuestro flujo de trabajo?


---

## Flujo de trabajo



&lt;img src="img/workflow-final.png" width="100%" style="display: block; margin: auto;" /&gt;



---
## Tunning de hiperpar치metros en 츼rboles de decisi칩n 

* Vamos a hacer tunning de los hiperpar치metros del modelo. 
Documentaci칩n: https://parsnip.tidymodels.org/reference/decision_tree.html 

 Hiperpar치metros del modelo:


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
* **cost_complexity**: Un n칰mero positivo para el par치metro de costo / complejidad 

* **tree_depth**: Un n칰mero entero para la profundidad m치xima del 치rbol.

* **min_n**: Un n칰mero entero para el n칰mero m칤nimo de puntos de datos en un nodo que se requieren para que el nodo se divida m치s.

]



---

### Valores por defecto




&lt;img src="img/rpart.png" width="90%" style="display: block; margin: auto;" /&gt;

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

* **Cuando aumenta el tree_depth aumenta la probabilidad de overfitting**

* **Cuando disminuye el min_n aumenta la probabilidad de overfitting**

* **Cuando se acerca a 0 el cost_complexity, aumenta la probabilidad de overfitting**

]



---
class: inverse, center, middle 

## 츼rboles de decisi칩n 

### 쮺칩mo se deciden los splits?



---


## Elecciones de dise침o


### Como dividir los splits

* Que medida o criterio como bondad de ajuste. 

* Splits binarios o multi-categ칩ricos.


### Cuando detenerse

* Si un nodo contiene exactamente ejemplos de la misma clase. 

* Los valores de los features son todos los mismos para las muestras. 


---

## ID3 - Iterative Dichotomizer 3

* Descripto por **Quinlan, J. R. (1986). Induction of decision trees. Machine learning, 1 (1), 81-106.**

* Uno de los primeros 치rboles de decisi칩n

* Features discretos, no puede manejar features num칠ricos. 

* Splits multi-categ칩ricos. 

* 츼rboles peque침os y amplios (a diferencia de CART).

* Maximiza **la ganancia de informaci칩n / minimiza la entrop칤a.**

* Features discretos, binarios y multi-categ칩ricos. 

---

## C4.5

* Descripto por **Quinlan, J. R. (1993). C4. 5: Programming for machine learning. Morgan Kauffmann, 38, 48.**

* Features continuos y discretos (los features continuos son costosos de computar ya que exigen todos los posibles rangos). 

* Criterio de split: **Gain Ratio**

* Puede manejar atributos (datos) faltantes (los ignora en el c칩mputo de la ganancia de informaci칩n). 

---

## CART

* Descripto por **Breiman, L. (1984). Classification and regression trees. Belmont, Calif:Wadsworth International Group.**

* Maneja features continuos y discretos. 

* Trabaja estrictamente con splits binarios (lo q resulta en 치rboles mas altos a diferencia de ID3 o C4.5)

* Los splits binarios puede generar mejores 치rboles que C4.5, pero tienden a ser m치s grandes y m치s dificiles de interpretar. 

* Reducci칩n de varianza en 치rboles de regresi칩n. 

* Utiliza la **impureza de Gini** en 치rboles de clasificaci칩n. 



---

## Entrop칤a

La entrop칤a es una medida de la aleatoriedad de la informaci칩n que se procesa. **Cuanto mayor sea la entrop칤a, m치s dif칤cil ser치 sacar conclusiones de esa informaci칩n.**

El concepto de entrop칤a viene del campo de la teor칤a de la informaci칩n. 


&lt;img src="img/entropy-math-eq.png" width="40%" style="display: block; margin: auto;" /&gt;


&lt;img src="img/entropy2.png" width="80%" style="display: block; margin: auto;" /&gt;


---

## Entrop칤a


&lt;img src="img/shannon.png" width="80%" style="display: block; margin: auto;" /&gt;



--
**A partir del gr치fico anterior, es bastante evidente que la entrop칤a es cero cuando la probabilidad es 0 o 1.** La entrop칤a es m치xima cuando la probabilidad es 0.5 porque proyecta una aleatoriedad perfecta en los datos y no hay posibilidad de determinar perfectamente el resultado. 



---

### Ganancia de Informaci칩n (Information Gain)


La ganancia de informaci칩n es una propiedad estad칤stica que mide qu칠 tan bien un atributo determinado separa los ejemplos de entrenamiento de acuerdo con su clasificaci칩n de destino. La construcci칩n de un 치rbol de decisiones consiste en encontrar un atributo que devuelva la **mayor ganancia de informaci칩n y la menor entrop칤a.**



`\(IG = Entropy(parent) - weighted \hspace{1mm} average [Entropy (children)]\)`


--



&lt;img src="img/IG.png" width="80%" style="display: block; margin: auto;" /&gt;


---

### Veamos como funciona en un 치rbol de decisi칩n 

Supongamos que tenemos que decidir si entregar o no un pr칠stamo, y tenemos 2 variables para decidir si lo hacemos:

* Balance: $$$$
* Residence: lugar de residencia. 


---


&lt;img src="img/entropy-balance.png" width="70%" style="display: block; margin: auto;" /&gt;


---


&lt;img src="img/entrop-balance.png" width="70%" style="display: block; margin: auto;" /&gt;


---


&lt;img src="img/entropy-residence.png" width="90%" style="display: block; margin: auto;" /&gt;


---




&lt;img src="img/entrop-residenc.png" width="80%" style="display: block; margin: auto;" /&gt;

---


## Conclusi칩n

Cuanto m치s homogeneas son las ramas del 치rbol que se genera al seleccionar el algoritmo una variable, 

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

* **hay mayor ganancia de informaci칩n.**

* **hay menos entrop칤a**

]



**Eso se traduce en un mejor modelo para la predicci칩n que deseamos realizar**


---

## Relaci칩n de Ganancia (Gain Ratio)


**La relaci칩n de Ganancia (Gain Ratio) es el cociente entre la ganancia de informaci칩n (Information Gain) y la entrop칤a del nodo ra칤z (root node).**

--



&lt;img src="img/gain.png" width="90%" style="display: block; margin: auto;" /&gt;


Recordar que se lo utiliza como criterio de impureza en C4.5


---

## Impureza de Gini

* **Medida de la impureza en CART** como contraposici칩n a la entrop칤a. 

&lt;img src="img/Gini-i.png" width="50%" style="display: block; margin: auto;" /&gt;

* En la pr치ctica, no importa si usamos entrop칤a o impureza de Gini, porque **ambos criterios tienen forma de campana.** 

* **Es m치s f치cil de computar Gini lo que hace que el c치lculo sea m치s eficiente en t칠rminos de rendimiento.** 


&lt;img src="img/impurity.png" width="50%" style="display: block; margin: auto;" /&gt;



---

class: inverse, center, middle

## Manos en R!


---

## Bibliograf칤a


* Abu-Mostafa, Y. Learning from data. 

* Kuhn, M. &amp; Johnson K. Applied Predictive Modeling.

* Provost, F &amp; Fawcett T. Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking

* Raschka, Sebastian. https://www.youtube.com/watch?v=z2n8kHXkwtM 

* Raschka, Sebastian. Apuntes de clase.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
