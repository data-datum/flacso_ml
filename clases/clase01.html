<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>clase01.utf8</title>
    <meta charset="utf-8" />
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


background-image: url(img/portada-flacso.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle



























# Machine Learning en Aplicaciones Espaciales


### Clase 1a: Generalidades. Conceptos Fundamentales



---

###  Hoja de Ruta üó∫

--
### Primer Parte ‚è∞

* Modelos de aprendizaje autom√°tico: fundamentos conceptuales (error de entrenamiento, error de generalizaci√≥n, balance sesgo-varianza), 
* Diferencias con el enfoque estad√≠stico tradicional.

--

#### Recreo  üçµ

--


### Segunda Parte  ‚è∞
* √Årboles de decisi√≥n + Pr√°ctica gu√≠ada

--

#### Recreo  üçµ

--

### Manos en R! üíª

---

## Campo de ML

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
El aprendizaje autom√°tico se trata de **extraer conocimiento de los datos** 
(*Andreas M√ºeller - Introduction to Machine Learning with Python*)
]

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

El aprendizaje autom√°tico se ocupa de la **construcci√≥n de algoritmos que, para ser √∫tiles, se basan en una colecci√≥n de ejemplos de alg√∫n fen√≥meno.** Los ejemplos pueden provenir de la naturaleza, ser recolectados por humanos o generados por otro algoritmo.

El aprendizaje autom√°tico tambi√©n se puede definir como el proceso de resoluci√≥n de un **problema pr√°ctico** mediante,
1) recopilar un conjunto de datos y
2) entrenar algor√≠tmicamente un modelo estad√≠stico basado en ese conjunto de datos
(*Andriy Burkov - Machine Learning Engineering*)
]


---

## ¬øQu√© es el aprendizaje autom√°tico?



.left-column[

* Subcampo de la inteligencia artificial. 

* Machine Learning vs Deep Learning

* Funciones convexas - no convexas
]

.right-column[

&lt;img src="img/AI-ml.png" width="60%" style="display: block; margin: auto;" /&gt;


]


---



## ML vs Deep learning

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
* Costo computacional. 

* Dificultad en el entrenamiento. 

* Ingenieria de features vs Ingenier√≠a de arquitecturas. 


]

## ML vs Data Science

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
* En ML se hace √©nfasis en el modelado de los datos (algoritmo, error, divisi√≥n de los datos), en la ciencia de datos, hacemos foco en todo el proceso desde la delimitaci√≥n del problema (problem framing) hasta su resoluci√≥n y despliegue*. 


]


---

## Cuando es apropiado utilizar ML para un problema

* Cuando el problema es muy complejo para programarlo. 


* Cuando el problema est√° constantemente cambiando.


* Cuando es un problema en el orden de la percepci√≥n (visi√≥n, lenguaje)


* Cuando es un fen√≥meno no estudiado. 


* Cuando es un problema con un objetivo simple.


.footnote[Fuente: *Machine Learning Engineering*]
---

## Tipos de aprendizaje
        
&lt;img src="img/ml.png" width="90%" style="display: block; margin: auto;" /&gt;



---

## Machine Learning Cl√°sico

        
&lt;img src="img/classicML.jpg" width="90%" style="display: block; margin: auto;" /&gt;


---

## Clasificaci√≥n

.left-column[

**Usado para:**

* Filtro de Spam (spam/jam)

* Detecci√≥n de lenguaje (espa√±ol, franc√©s, etc)

* An√°lisis de sentimientos (positivo/negativo)

* Reconocer d√≠gitos escritos a mano (0 al 9)


]

.right-column[

&lt;img src="img/classification.jpg" width="60%" style="display: block; margin: auto;" /&gt;


]



---


## Regresi√≥n 


.left-column[

**Usado para:**

* Predicci√≥n de precios de casas seg√∫n variables geogr√°ficas

* Establecer relaciones entre el ingreso y variables demogr√°ficas

* Predicci√≥n de accidentes automovil√≠sticos


]

.right-column[

&lt;img src="img/regression.jpg" width="60%" style="display: block; margin: auto;" /&gt;


]



---

## Aprendizaje supervisado (1)


&lt;img src="img/supervised1.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *Machine Learning with R, the tidyverse and mlr*]



---



## Aprendizaje supervisado (2)

&lt;img src="img/supervised.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *Machine Learning with R, the tidyverse and mlr*]



---


## Clusterizado (clustering)



.left-column[

**Usado para:**

*  Segmentaci√≥n de mercado (tipo de consumidores, lealtad)

*  Analizar y agregar un r√≥tulo en nuevos datos. 



]

.right-column[

&lt;img src="img/clustering.jpg" width="60%" style="display: block; margin: auto;" /&gt;


]



---

## Reducci√≥n de dimensiones



.left-column[

**Usado para:**

- Sistemas de recomendaci√≥n 

- Visualizaci√≥n del problema que nos interesa. 

- Modelado de t√≥picos




]

.right-column[

&lt;img src="img/PCA.jpg" width="60%" style="display: block; margin: auto;" /&gt;


]


---

## Aprendizaje no supervisado (1)


&lt;img src="img/unsupervised1.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *Machine Learning with R, the tidyverse and mlr*]




---

## Aprendizaje no supervisado (2)


&lt;img src="img/unsupervised.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *Machine Learning with R, the tidyverse and mlr*]





---

## Conceptos Importantes üí°

* __Muestra, punto, observaci√≥n, instancia__ se refiere a una unidad de an√°lisis.
&lt;br&gt;

* __Set de entrenamiento__ son los datos utilizados para el modelado. 
&lt;br&gt;

* __Set de prueba__ son los datos utilizados para medir el desempe√±o del modelo, entre un conjunto de candidatos. 
&lt;br&gt;

* __Atributos, predictores, features, variables independientes o descriptores__ son los datos de entrada para la ecuaci√≥n de predicci√≥n.
&lt;br&gt; 
* __Salida, variable dependiente, variable respuesta, clase, o "target"__ es la cantidad/clase a ser predicha. 
&lt;br&gt;



.footnote[Fuente: *Applied Predictive Modeling*]



---

## Conceptos Importantes üí°


* __Par√°metros__ son variables que definen el modelo entrenado mediante aprendizaje. Los par√°metros son directamente modificados por el algoritmo de aprendizaje basado en los datos de entrenamiento. Ej, la pendiente y la ordenada de una recta en regresi√≥n lineal simple. 
&lt;br&gt;

* __Hiperpar√°metros__ son *variables internas* de un algoritmo de ML que influencian la performance del modelo. No pueden ser aprendidos mediante el algoritmo de ML, ya que son definidos por el usuario, aunque lo m√°s com√∫n es realizar una b√∫squeda de hiperpar√°metros (en grilla o de manera aleatoria son las formas de b√∫squeda m√°s comunes).
Ej: profundidad de un √°rbol en √°rboles de decisi√≥n, el K √≥ptima en KNN.


.footnote[Fuente: *Machine Learning Engineering*]


---

## Modelado. Las dos culturas



&lt;img src="img/leo-b.png" width="70%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *http://www2.math.uu.se/~thulin/mm/breiman.pdf*]


---

## Modelado Estad√≠stico


  
&lt;img src="img/stats-model.png" width="50%" style="display: block; margin: auto;" /&gt;


* √ânfasis en f(x). El modelo se postula en base a supuestos sobre f(x)
* Conocimiento acumulado, teor√≠a, dise√±o de experimentos.
* Los par√°metros son estimados con los datos y luego se realizan las
predicciones.
* Evaluaci√≥n del modelo: estimadores insesgados, robustos, m√≠nima
varianza. 


.footnote[Fuente: *http://www2.math.uu.se/~thulin/mm/breiman.pdf*]

---

## Modelado Algor√≠tmico (a.k.a ML)


  
&lt;img src="img/alg-model.png" width="50%" style="display: block; margin: auto;" /&gt;



* √ânfasis en la predicci√≥n. 
* El enfoque es encontrar una funci√≥n f (x) -un algoritmo- que opera
sobre las x para predecir las y.
* El modelo se ‚Äúaprende‚Äù de los datos
* Evaluaci√≥n del modelo: performance predictiva


.footnote[Fuente: *http://www2.math.uu.se/~thulin/mm/breiman.pdf*]




---



### Etapas de un problema de machine learning supervisado (1)


* **Definir el problema** ¬øQu√© se pretende predecir? ¬øDe qu√© datos se dispone? o ¬øQu√© datos es necesario conseguir?

* **Explorar y entender los datos** que se van a emplear para crear el modelo.

* **Preprocesar los datos** aplicar las transformaciones necesarias para que los datos puedan ser interpretados por el algoritmo de machine learning seleccionado.

* **M√©trica de √©xito** definir una forma apropiada de cuantificar c√≥mo de buenos son los resultados obtenidos.

* **Preparar la estrategia para evaluar el modelo** separar las observaciones en un conjunto de entrenamiento, un conjunto de validaci√≥n (o validaci√≥n cruzada) y un conjunto de test. Es muy importante asegurar que ninguna informaci√≥n del conjunto de test participa en el proceso de entrenamiento del modelo.




---

### Etapas de un problema de machine learning supervisado (2)

* **Ajustar un primer modelo** capaz de superar unos resultados m√≠nimos. Por ejemplo, en problemas de clasificaci√≥n, el m√≠nimo a superar es el porcentaje de la clase mayoritaria (la moda).

* Gradualmente, **mejorar el modelo** incorporando-creando nuevas variables u optimizando los hiperpar√°metros.

* **Evaluar la capacidad del modelo final** con el conjunto de test para tener una estimaci√≥n de la capacidad que tiene el modelo cuando predice nuevas observaciones.



.footnote[Fuente: *https://www.cienciadedatos.net/documentos/59_machine_learning_con_r_y_tidymodels*]
---



## ¬øQu√© es EDA? üîé

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
### **EDA** o An√°lisis Exploratorio de Datos 

#### es un ciclo iterativo y un proceso creativo en donde, 

#### - **Generas preguntas acerca de tus datos.**

#### - **Buscas respuestas mediante la visualizaci√≥n y transformaci√≥n de los mismos.**

#### - **En base a lo aprendido, refinas tus preguntas e incluso, generas nuevas.**

]
.footnote[Fuente:*[R para Ciencia de  Datos](https://es.r4ds.hadley.nz/an%C3%A1lisis-exploratorio-de-datos-eda.html)]*

---

## Cobran especial importancia en esta etapa


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Estudio de la distribuci√≥n de las variables

#### Presencia de valores perdidos

#### Desbalance de las clases o grupos en estudio

#### Presencia de datos extremos o outliers 

#### Covariaci√≥n/correlaci√≥n de variables

]

.footnote[Fuente: *[R para Ciencia de  Datos](https://es.r4ds.hadley.nz/an%C3%A1lisis-exploratorio-de-datos-eda.html)]*
---

## ¬øPor qu√© es importante el An√°lisis exploratorio de datos? üí°

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt5[

### Porque te permite conocer y entender tus datos. ]





---

### Curaci√≥n de datos üöë

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
### **Curaci√≥n de Datos** o Ingenier√≠a de Features 

#### es una etapa en la cual **seleccionamos** y **transformamos** las variables 

#### - **Puede haber combinaci√≥n de datasets (enriquecimiento)**

#### - **Vemos que variables son relevantes (feature selection)**

#### - **Limpieza de datos (inconsistencias)**

]




---


## Cobran especial importancia en esta etapa


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Imputaci√≥n de datos ruidosos, perdidos o err√≥neos. 

#### Codificaci√≥n de variables categ√≥ricas. 

#### Transformaci√≥n de variables.

#### Ingenier√≠a de outliers. 

#### Escalado de Features

#### Discretizaci√≥n de variables (continuas ---&gt; discretas)

]



---

## ¬øPor qu√© es importante la Curaci√≥n de datos? üí°

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt5[

### Porque permite transformar los datos para que tengan una forma adecuada para modelarlos.

### Tener en cuenta que en esta etapa siempre se introduce SESGO.

]


---


## Modelado Algor√≠tmico - ML

Podemos decir que modelar (mediante ML) implica pensar en todos estos aspectos:

* Train - test split (C√≥mo vamos a dividir los datos)
* Complejidad / Interpretabilidad del modelo. 
* Error de entrenamiento - error de generalizaci√≥n
* M√©tricas
* Underfitting - Overfitting




---

## Train - Test Split

#### Opci√≥n 1: Holdout 
La manera m√°s simple de dividir un dataset es dividirlo en TRAIN y TEST. 

&lt;img src="img/holdout-dataset.png" width="70%" style="display: block; margin: auto;" /&gt;



---



## Entrenamiento, validaci√≥n y testeo

#### Opci√≥n 2: Dividir en 3 partes el dataset

&lt;img src="img/train-val-test.jpeg" width="40%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *https://www.tmwr.org/resampling.html*]




---

## Resampleo 

#### Opci√≥n 3: Hacer validaci√≥n cruzada. 

&lt;img src="img/resampling.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *https://www.tmwr.org/resampling.html*]

---


## Validaci√≥n cruzada




&lt;img src="img/CV.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *https://www.tmwr.org/resampling.html*]

---


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
### La validaci√≥n cruzada se utiliza para estimar el error de generalizaci√≥n de un modelo y tambi√©n para hacer optimizaci√≥n de hiperpar√°metros. 
 
]




---
## Bootstraping 



&lt;img src="img/bootstrap.png" width="100%" style="display: block; margin: auto;" /&gt;





.footnote[Fuente: *https://www.tmwr.org/resampling.html*]
---


.bg-near-white.b--purple.ba.bw2.br3.shadow-5.ph4.mt5[
### Tanto validaci√≥n cruzada como bootstrap son t√©cnicas de resampleo (resampling).
### La diferencia radica en que la validaci√≥n cruzada no es con reemplazo mientras que bootstrap s√≠ lo es. 
]







---

## Modelos 

*Interpretabilidad vs Flexibilidad*

&lt;img src="img/models.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *Introduction to Statistical Learning*]

---

## M√©tricas


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Durante el modelado de datos es probable que no hagamos un solo modelo, sino varios. 
#### La manera de saber qu√© tan buenos son, es evaluar esos algoritmos mediante m√©tricas.
#### Tenemos m√©tricas de regresi√≥n y clasificaci√≥n.
&lt;br&gt;

]

---

### M√©tricas para Regresi√≥n

* Mean Square Error (MSE)


&lt;img src="img/mse.jpg" width="40%" style="display: block; margin: auto;" /&gt;


* Root Mean Square Error (RMSE)


&lt;img src="img/rmse.png" width="40%" style="display: block; margin: auto;" /&gt;



* Mean Absolute Error (MAE)


&lt;img src="img/mae-n.jpg" width="50%" style="display: block; margin: auto;" /&gt;



---

### M√©tricas para Clasificaci√≥n

Supongamos que se desea realizar una clasificaci√≥n en la que disponemos de dos clases etiquetadas como Positivo y Negativo. 

A su vez, disponemos de un modelo en el cual las predicciones no coinciden 100% con las clases verdaderas. 
  
&lt;img src="img/metricas1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

### Positivos verdaderos
     
  
&lt;img src="img/metricas2.png" width="100%" style="display: block; margin: auto;" /&gt;


---

### Falsos Negativos 
  
&lt;img src="img/metricas3.png" width="100%" style="display: block; margin: auto;" /&gt;


---

### Negativos verdaderos
  
&lt;img src="img/metricas4.png" width="100%" style="display: block; margin: auto;" /&gt;

---

### Falsos Positivos 
  
&lt;img src="img/metricas5.png" width="100%" style="display: block; margin: auto;" /&gt;



---

## Matriz de Confusi√≥n

Todo lo anterior puede resumirse en la Matriz de Confusi√≥n
      
  
&lt;img src="img/matriz-confusion.png" width="100%" style="display: block; margin: auto;" /&gt;

    


.footnote[Traducido de 10.7717/peerj.5666/fig-2]



---

## Precision vs Sensibilidad (Recall) 

* Uno podria elegir trabajar con las m√©tricas de Precision o Recall para un problema desbalanceado. 
Maximinar la precisi√≥n minimizar√° los FALSOS POSITIVOS, mientras que el Recall minimizar√° los FALSOS
NEGATIVOS. 
* Entonces, podria ser adecuado trabajar con:

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Precisi√≥n: Cuando el objetivo es minimizar los falsos positivos. 


#### Sensibilidad (Recall): Cuando el objetivo es minimizar los falsos negativos. 


]


---

### Importante  üí°


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

### La accuracy o exactitud es una m√©trica apropiada en datasets balanceados. 

### En caso de estar lidiando con datasets desbalanceados deberemos usar la m√©trica apropiada (o balancear nuestros datos).  

]

.footnote[*https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/*]


---

### Importante  üí°


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

## Determinar que error es m√°s grave (FP o FN) lo determina el contexto de aplicaci√≥n del problema.

Veamos un ejemplo pr√°ctico
]


---

## FP vs FN



&lt;img src="img/cia-market.png" width="70%" style="display: block; margin: auto;" /&gt;


Consideremos dos clientes potenciales de un sistema de huellas dactilares. 

* Uno es un **supermercado** que lo usar√° en el mostrador de pago para verificar que usted es miembro
de un programa de descuento. 
* El otro es la **CIA** que lo usar√° en la entrada de una instalaci√≥n, para verificar que Ud es personal autorizado para ingresar a esa instalaci√≥n.

.footnote[Fuente: *Learning from data*]
---

### FP vs FN


* Para el supermercado, un **falso rechazo (falso negativo) es costoso** porque si un cliente recibe un 
rechazo err√≥neamente, puede desanimarse de seguir siendo cliente en el futuro. 
* Por otro lado, el costo de una **falsa aceptaci√≥n (falso positivo) es menor**. El supermercado regala un descuento a alguien que no se lo merec√≠a, sin mayores prejuicios para el supermercado. 


.footnote[Fuente: *Learning from data*]

--



&lt;img src="img/MARKET.png" width="100%" style="display: block; margin: auto;" /&gt;



.footnote[Fuente: *Learning from data*]

---

### FP vs FN

* Para la CIA, sin embargo, una **falsa aceptaci√≥n (falso positivo) es un desastre**. Una persona no autorizada se beneficiar√° del acceso a una instalaci√≥n muy sensible. 
* **El falso rechazo (falso negativo)**, sin embargo, **puede tolerarse**, ya que las personas autorizadas son empleados (en lugar de clientes como el caso del supermercado).


.footnote[Fuente: *Learning from data*]

--



&lt;img src="img/CIA.png" width="100%" style="display: block; margin: auto;" /&gt;


.footnote[Fuente: *Learning from data*]

---

### Curvas ROC

La curva ROC (receiver operating characteristic) relaciona el recall con el ratio de falsos positivos. Es decir relaciona la sensibilidad de nuestro modelo con los fallos optimistas (clasificar los negativos como positivos). Tiene sentido ya que, generalmente, si aumentamos el recall, nuestro modelo tender√° a ser m√°s optimista e introducir√° mas falsos positivos en la clasificaci√≥n.

En las curvas ROC, nos interesa que la curva se acerque lo m√°ximo posible a la esquina superior izquierda de la gr√°fica, de manera que el hecho de aumentar la sensibilidad (el recall) no haga que nuestro modelo introduzca m√°s falsos positivos.

El AUC es conveniente por las dos razones siguientes:

* El AUC es invariable con respecto a la escala. Mide qu√© tan bien se clasifican las predicciones, en lugar de sus valores absolutos.
* El AUC es invariable con respecto al umbral de clasificaci√≥n. Mide la calidad de las predicciones del modelo, sin tener en cuenta qu√© umbral de clasificaci√≥n se elige.


.footnote[Fuente: *https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=es*]


---

### Curvas ROC




&lt;img src="img/roc-auc.png" width="50%" style="display: block; margin: auto;" /&gt;


La curva ROC nos permite obtener el AUC o √°rea bajo la curva. El AUC oscila en valor del 0 al 1. Un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0; otro cuyas predicciones son un 100% correctas tiene un AUC de 1.0.


.footnote[Fuente: *https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=es*]



---

## 


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt5[

La curva ROC es independiente del umbral seleccionado.

]

![](https://raw.githubusercontent.com/dariyasydykova/open_projects/master/ROC_animation/animations/cutoff.gif) 


.footnote[Fuente: *https://paulvanderlaken.com/2019/08/16/roc-auc-precision-and-recall-visually-explained/*]

---

## ¬øQu√© significa que sea independiente del umbral seleccionado?

Supongamos que tenemos un modelo de clasificaci√≥n binaria 

&lt;img src="img/thresh-01.png" width="100%" style="display: block; margin: auto;" /&gt;

--


&lt;img src="img/thesh02.png" width="100%" style="display: block; margin: auto;" /&gt;


---


&lt;img src="img/thresh03.png" width="100%" style="display: block; margin: auto;" /&gt;

--


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt5[

Vamos a buscar clasificadores que rankeen:
* **alto en Y**, es decir que tengan una alta sensibilidad (recall), o alta tasa de verdaderos positivos, y
* **bajo en X**, es decir, valores bajos en falsos positivos. 

]

---

## ¬øCu√°l de estas curvas es ROC tiene mejor performance?

 
&lt;img src="img/roc-question.png" width="70%" style="display: block; margin: auto;" /&gt;



---

### Underfitting - Overfitting

  
&lt;img src="img/under-over.png" width="80%" style="display: block; margin: auto;" /&gt;

.footnote[*https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks*]

---

### Underfitting

Cuando un modelo comete muchos errores en el entrenamiento, decimos que tienen un **alto bias**, que underfittea o que el ajuste es pobre. Esto se puede presentar debido a:

* El modelo es muy simple para los datos. 
* Los features, variables (columnas) son poco informativos sobre el problema. 

*Posibles soluciones:*

* Probar un modelo m√°s complejo. 
* Mejores Features
* Conseguir m√°s datoss.

.footnote[*Machine Learning Engineering*]
---

### Overfitting

Cuando un modelo tiene una buena performance en el set de validaci√≥n pero mala perfomance en test, se dice que el modelo **sobreajusta u overfittea**. Tambi√©n se dice, que el modelo *memoriza* los datos de entrenamiento por eso no generalizar√° bien frente a nuevos datos.  Un modelo que sobreajusta, tiene una **alta varianza**

* El modelo es muy complejo para los datos. 
* Los features, variables (columnas) son muchas para la cantidad de filas. 

*Posibles soluciones:*

* Probar un modelo m√°s simple. 
* Menos Features
* Conseguir m√°s datos.



.footnote[*Machine Learning Engineering*]

---

### Importante

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

### El objetivo de un modelo de ML siempre es que pueda generalizar bien frente a nuevos datos o datos no vistos por el modelo. 


]



---

## Bias - Variance tradeoff

En la pr√°ctica, por reducir la varianza, se incrementa el bias, y viceversa. En otras palabras, por reducir el overfitting se aumenta el underfitting y viceversa. A esto llamamos bias-variance tradeoff. Por tener un modelo que ajuste de manera perfecta el set de training terminamos con un modelo pobre para los datos de test. 

  
&lt;img src="img/bias-variance22.png" width="50%" style="display: block; margin: auto;" /&gt;



.footnote[*Machine Learning Engineering*]

---

### Sesgo - varianza



&lt;img src="img/bias-variance2.png" width="60%" style="display: block; margin: auto;" /&gt;



---


## Bias - Variance tradeoff
(Balance sesgo-varianza)

&lt;img src="img/bias-variance.png" width="80%" style="display: block; margin: auto;" /&gt;


*Para una introducci√≥n visual ver: http://www.r2d3.us/visual-intro-to-machine-learning-part-2/*




.footnote[*Machine Learning with R, the tidyverse and mlr*]
---

class: inverse, center, middle

## Software



---

## De caret a `tidymodels`



.pull-left[
El objetivo de caret era **unificar la sintaxis** para modelizar datos usando como base distintas librer√≠as de R. 
&lt;img src="img/caret.png" width="100%" align="right" /&gt;
]

--

.pull-right[
El objetivo de Tidymodels es adem√°s hacerlo **en un formato ordenado**. 
&lt;img src="img/tidymodels.png" width="80%" align="right" /&gt;

]



---

### Etapas del modelado de datos


  
&lt;img src="img/modeling.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[Fuente: *https://www.tmwr.org/software-modeling.html*]


---

### `tidymodels`


&lt;img src="img/tidy-w.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Librer√≠as de `tidymodels`


.left-column[
### `library(rsample)`
__Librer√≠a que nos permite hacer divisi√≥n del set de datos__

]

.right-column[

&lt;img src="img/rsample.png" width="40%" style="display: block; margin: auto;" /&gt;

]





---

## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
### `library(recipes)`
__Permite hacer preprocesamiento de los datos__
]

.right-column[

&lt;img src="img/recipes.png" width="40%" style="display: block; margin: auto;" /&gt;


]

---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
### `library(parsnip)`
__Permite unificar los modelos a optimizar__
]

.right-column[

&lt;img src="img/parsnip.png" width="40%" style="display: block; margin: auto;" /&gt;


]


---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
### `library(workflows)`
__Nos permite unificar el flujo de trabajo__

]

.right-column[

&lt;img src="img/workflow.png" width="40%" style="display: block; margin: auto;" /&gt;


]


---
## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
#### `library(workflows)`
### `library(tune)`
__Permite el tuneo de los hiperpar√°metros de los modelos__
]

.right-column[

&lt;img src="img/tune.png" width="40%" style="display: block; margin: auto;" /&gt;


]



---

## Librer√≠as de `tidymodels`

.left-column[
#### `library(rsample)`
#### `library(recipes)`
#### `library(parsnip)`
#### `library(workflows)`
#### `library(tune)`
### `library(yardstick)`
__Permite evaluar las m√©tricas de los modelos__
]

.right-column[

&lt;img src="img/yardstick.png" width="40%" style="display: block; margin: auto;" /&gt;


]





---

## Bibliograf√≠a


* Introduction to Statistical Learning. 
https://www.statlearning.com/ 

* Applied Predictive Modelling

* Learning from data

* Tidy Modeling with R. https://www.tmwr.org/ 

* Breimann, L. Statistical Modeling: The Two Cultures (paper)
http://www2.math.uu.se/~thulin/mm/breiman.pdf 

* Mehta, P. et al. A high-bias, low-variance introduction to Machine Learning
for physicists (paper)
https://www.sciencedirect.com/science/article/pii/S0370157319300766 

* Im√°genes tomadas de https://vas3k.com/blog/machine_learning/ 

* Machine Learning Engineering http://www.mlebook.com/wiki/doku.php 


---

class: center, middle


## üîó
## Para ver en web estas slides

https://data-datum.github.io/flacso_ml/clases/clase01.html#1
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
