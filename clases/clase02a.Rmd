---
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

background-image: url(img/portada-flacso.png)
background-size: cover
class: animated slideInRight fadeOutLeft, middle

```{r xaringan-extra-styles, include=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```



```{r , echo=FALSE}
xaringanExtra::use_tachyons()
xaringanExtra::use_panelset()
```


```{r include=FALSE}
library(countdown)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
#style_duo_accent(
#  primary_color = "#23395b",
#  secondary_color = "#23395b",
#  inverse_header_color = "#FFFFFF"
#)

style_duo_accent(
  header_font_google = google_font("Roboto", "500"),
  text_font_google   = google_font("Roboto", "400", "300i"),
  code_font_google   = google_font("Roboto")
)
```


```{r, message=FALSE, warning=FALSE, include=FALSE}
style_mono_accent(base_color = "#43418A")
```

```{r , message=FALSE, warning=FALSE, include=FALSE} 
library(fontawesome)
library(emo)
```


```{r xaringan-logo, echo=FALSE}
#xaringanExtra::use_fit_screen()
#xaringanExtra::use_logo("img/logo-tidymodels.png")
```



```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
xaringanExtra::use_fit_screen()
```


# Machine Learning en Aplicaciones Espaciales


### Clase 2a



---

## Que vemos hoy


### Repaso de Métricas 
#### F1 score y AUC


### Repaso de árboles 


### Random Forest (teoría y práctica)


---

# Repaso de Métricas

---


## Matriz de confusión

        
```{r echo=FALSE, out.width = '90%',  fig.align='center'}
knitr::include_graphics("img/conf-m.png")
```


---

## Exactitud (accuracy)
        
```{r echo=FALSE, out.width = '90%',  fig.align='center'}
knitr::include_graphics("img/conf-m2.png")
```



---

## Precision

        
```{r echo=FALSE, out.width = '90%',  fig.align='center'}
knitr::include_graphics("img/conf-m3.png")
```


---

## Recall

       
```{r echo=FALSE, out.width = '90%',  fig.align='center'}
knitr::include_graphics("img/conf-m4.png")
```


---

## Repaso

       
```{r echo=FALSE, out.width = '90%',  fig.align='center'}
knitr::include_graphics("img/metrics00.png")
```

---



## Precision vs Recall 

* Uno podria elegir trabajar con las métricas de Precision o Recall para un problema desbalanceado. 
Maximinar la precisión minimizará los FALSOS POSITIVOS, mientras que el Recall minimizará los FALSOS
NEGATIVOS. 
* Entonces, podria ser adecuado trabajar con:

.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

#### Precisión: Cuando el objetivo es minimizar los falsos positivos. 


#### Recall: Cuando el objetivo es minimizar los falsos negativos. 


]



---

## F1 score


Cuando me interesan tanto los FP como los FN, de igual forma, voy a utilizar el F1-score. 

<br><br><br>
```{r echo=FALSE, out.width = '80%',  fig.align='center'}
knitr::include_graphics("img/f1.svg")
```

.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---

### Entendamos el F1-Score

Supongamos que tenemos una máquina recolectora de frutas, siendo que algunas de ellas están maduras y otras no. 


  
```{r echo=FALSE, out.width = '80%',  fig.align='center'}
knitr::include_graphics("img/ripe-apples.png")
```



.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]

---


```{r echo=FALSE, out.width = '50%',  fig.align='center'}
knitr::include_graphics("img/apple-ripe2.png")
```



```{r echo=FALSE, out.width = '80%',  fig.align='center'}
knitr::include_graphics("img/f1-c.png")
```


.footnote[*https://deepai.org/machine-learning-glossary-and-terms/f-score*]


---

### Importante  `r emo::ji("bulb")`


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

### La accuracy o exactitud es una métrica apropiada en datasets balanceados. 

### En caso de estar lidiando con datasets desbalanceados deberemos usar la métrica apropiada (o balancear nuestros datos).  

]

.footnote[*https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/*]


---

### Importante  `r emo::ji("bulb")`


.bg-near-white.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

## Determinar que error es más grave (FP o FN) lo determina el contexto de aplicación del problema.

Veamos un ejemplo práctico
]


---

## FP vs FN



```{r echo=FALSE, out.width = '70%',  fig.align='center'}
knitr::include_graphics("img/cia-market.png")
```


Consideremos dos clientes potenciales de un sistema de huellas dactilares. 

* Uno es un **supermercado** que lo usará en el mostrador de pago para verificar que usted es miembro
de un programa de descuento. 
* El otro es la **CIA** que lo usará en la entrada de una instalación, para verificar que Ud es personal autorizado para ingresar a esa instalación.

.footnote[Fuente: *Learning from data*]
---

### FP vs FN


* Para el supermercado, un **falso rechazo (falso negativo) es costoso** porque si un cliente recibe un 
rechazo erróneamente, puede desanimarse de seguir siendo cliente en el futuro. 
* Por otro lado, el costo de una **falsa aceptación (falso positivo) es menor**. El supermercado regala un descuento a alguien que no se lo merecía, sin mayores prejuicios para el supermercado. 


.footnote[Fuente: *Learning from data*]

--



```{r echo=FALSE, out.width = '100%',  fig.align='center'}
knitr::include_graphics("img/MARKET.png")
```



.footnote[Fuente: *Learning from data*]

---

### FP vs FN

* Para la CIA, sin embargo, una **falsa aceptación (falso positivo) es un desastre**. Una persona no autorizada se beneficiará del acceso a una instalación muy sensible. 
* **El falso rechazo (falso negativo)**, sin embargo, **puede tolerarse**, ya que las personas autorizadas son empleados (en lugar de clientes como el caso del supermercado).


.footnote[Fuente: *Learning from data*]

--



```{r echo=FALSE, out.width = '100%',  fig.align='center'}
knitr::include_graphics("img/CIA.png")
```


.footnote[Fuente: *Learning from data*]



---


## Curva AUC



---


## Repaso de Àrboles


---

## Ventajas y Desventajas

---


## Ventajas


* Los árboles son fáciles de interpretar aun cuando las relaciones entre predictores son complejas.

* Los modelos basados en un solo árbol (no es el caso de Random Forest y Boosting) se pueden representar gráficamente aun cuando el número de predictores es mayor de 3.

* Los árboles pueden, en teoría, manejar tanto predictores numéricos como categóricos sin tener que crear variables dummy o one-hot-encoding. En la práctica, esto depende de la implementación del algoritmo que tenga cada librería.

* Al tratarse de métodos no paramétricos, no es necesario que se cumpla ningún tipo de distribución específica.

* Por lo general, requieren mucha menos limpieza y preprocesado de los datos en comparación con otros métodos de aprendizaje estadístico (por ejemplo, no requieren estandarización).

---

## Ventajas 

* No se ven muy influenciados por outliers.

* Si para alguna observación, el valor de un predictor no está disponible, a pesar de no poder llegar a ningún nodo terminal, se puede conseguir una predicción empleando todas las observaciones que pertenecen al último nodo alcanzado. La precisión de la predicción se verá reducida pero al menos podrá obtenerse.

* Son muy útiles en la exploración de datos, permiten identificar de forma rápida y eficiente las variables (predictores) más importantes.

* Son capaces de seleccionar predictores de forma automática.

* Pueden aplicarse a problemas de regresión y clasificación.


---

## Desventajas

* La capacidad predictiva de los modelos basados en un único árbol es bastante inferior a la conseguida con otros modelos. Esto es debido a su tendencia al overfitting y alta varianza. Sin embargo, existen técnicas más complejas que, haciendo uso de la combinación de múltiples árboles (bagging, random forest, boosting), consiguen mejorar en gran medida este problema.

* Son sensibles a datos de entrenamiento desbalanceados (una de las clases domina sobre las demás).

* Cuando tratan con predictores continuos, pierden parte de su información al categorizarlos en el momento de la división de los nodos.

* Tal y como se describe más adelante, la creación de las ramificaciones de los árboles se consigue mediante el algoritmo de recursive binary splitting. Este algoritmo identifica y evalúa las posibles divisiones de cada predictor acorde a una determinada medida (RSS, Gini, entropía…). Los predictores continuos tienen mayor probabilidad de contener, solo por azar, algún punto de corte óptimo, por lo que suelen verse favorecidos en la creación de los árboles.

* No son capaces de extrapolar fuera del rango de los predictores observado en los datos de entrenamiento.

---




